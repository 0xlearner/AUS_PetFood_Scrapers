{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import html\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "now = datetime.now()\n",
    "today = date.today()\n",
    "\n",
    "\n",
    "class PetSmart:\n",
    "\n",
    "    results = []\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:108.0) Gecko/20100101 Firefox/108.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Sec-GPC\": \"1\",\n",
    "    }\n",
    "\n",
    "    async def fetch_ids(self, client, url):\n",
    "        print(f\"Fetching product ID's from: {url}\", end=\"\")\n",
    "        response = await client.get(url, headers=self.headers)\n",
    "        print(f\" | Status code: {response.status_code}\")\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        json_text = [\n",
    "            id[\"data-gtm-product-click\"]\n",
    "            for id in soup.find_all(\"div\", {\"class\": \"product-tile\"})\n",
    "        ]\n",
    "        prod_ids = [json.loads(j)[\"id\"] for j in json_text]\n",
    "\n",
    "        return prod_ids\n",
    "\n",
    "    async def parse_product_details(self, client, product_url: str):\n",
    "        item = {}\n",
    "        print(f\"Parsing product details from: {product_url}\", end=\"\")\n",
    "        response = await client.get(product_url, headers=self.headers)\n",
    "        print(f\" | Status code: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            item['Scraped_Date'] = now.strftime(\"%m/%d/%Y, %H:%M:%S\").split(\",\")[0]\n",
    "            item['Scraped_Time'] = now.strftime(\"%m/%d/%Y, %H:%M:%S\").split(\",\")[1]\n",
    "            item[\"Product\"] = data[\"name\"]\n",
    "            try:\n",
    "                item[\"Flavor\"] = data[\"variation_values\"][\"customFlavor\"]\n",
    "            except Exception as e:\n",
    "                print(f\"{product_url} does not have {e}\")\n",
    "                item[\"Flavor\"] = \"N/A\"\n",
    "\n",
    "            for var in data[\"variants\"]:\n",
    "                item[var[\"variation_values\"][\"size\"]] = var[\"price\"]\n",
    "                try:\n",
    "                    item[f'{var[\"variation_values\"][\"size\"]}_offer_price'] = data[\n",
    "                        \"prices\"\n",
    "                    ][\"ps-us-sale-pricebook\"]\n",
    "                except:\n",
    "                    item[f'{var[\"variation_values\"][\"size\"]}_offer_price'] = \"N/A\"\n",
    "                item[f'{var[\"variation_values\"][\"size\"]}_recommended_price'] = data[\n",
    "                    \"prices\"\n",
    "                ][\"ps-us-list-pricebook\"]\n",
    "            try:\n",
    "                item[\"Grain_Free\"] = (\n",
    "                    \"Yes\" if \"Grain Free\" in data[\"c_customNutritionalOption\"] else \"No\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"{product_url} does not have {e}\")\n",
    "                item[\"Grain_Free\"] = \"N/A\"\n",
    "            description = [\n",
    "                d.strip()\n",
    "                for d in re.sub(\n",
    "                    \"<[^<]+?>\", \" \", html.unescape(data[\"long_description\"])\n",
    "                )\n",
    "                .strip()\n",
    "                .split(\"\\r\\n\\r\\n\")\n",
    "            ]\n",
    "            life_stage = [l.strip() for l in description[0].split(\"\\r\\n\")]\n",
    "            for stage in life_stage:\n",
    "                if stage.startswith(\"Life Stage\"):\n",
    "                    item[\"Life_Stage\"] = stage.split(\":\")[-1].strip()\n",
    "            for ingredients in description:\n",
    "                if ingredients.startswith(\"Ingredients\"):\n",
    "                    item[\"Ingredients\"] = ingredients.split(\":\")[-1].strip()\n",
    "            item[\"URL\"] = product_url\n",
    "            item[\"Rating\"] = data[\"c_bvAverageRating\"]\n",
    "            item[\"Reviews\"] = data[\"c_bvReviewCount\"]\n",
    "            self.results.append(item)\n",
    "\n",
    "    def to_csv(self):\n",
    "        df = pd.DataFrame(self.results)\n",
    "        df.to_csv(f\"petsmart_2_{today}.csv\", index=False)\n",
    "        print('Stored results to \"petsmart_2.csv\"')\n",
    "\n",
    "    async def run(self):\n",
    "        async with httpx.AsyncClient(timeout=30) as client:\n",
    "            for page in range(1, 4):\n",
    "                page_no = page * 36\n",
    "                base_url = f\"https://www.petsmart.com/dog/food/royal-canin+royal-canin-veterinary-diet/?pmin=0.01&srule=best-sellers&start={page_no}&sz=36&format=ajax\"\n",
    "                product_ids = await self.fetch_ids(client, base_url)\n",
    "                product_urls = [\n",
    "                    f\"https://www.petsmart.com/dw/shop/v18_8/products/{product_id}?client_id=11d422c1-e017-4692-8ade-c0d36191da29&expand=prices,variations,availability,promotions,options\"\n",
    "                    for product_id in product_ids\n",
    "                ]\n",
    "\n",
    "                tasks = [\n",
    "                    asyncio.create_task(self.parse_product_details(client, url))\n",
    "                    for url in product_urls\n",
    "                ]\n",
    "\n",
    "                await asyncio.gather(*tasks)\n",
    "\n",
    "                self.to_csv()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    scraper = PetSmart()\n",
    "    scraped_data = loop.run_until_complete(scraper.run())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16 (main, Dec  7 2022, 01:11:51) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a341ce109544d6e2a0814618519ed9eeb5e13f6b29513a0c38b83ef52ba90fb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
